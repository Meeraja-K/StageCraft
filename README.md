
VR Public Speaking Tool:

StageCraft is a VR Public Speaking Practice Tool designed to help users enhance their public speaking skills by simulating realistic environments such as auditoriums or conference rooms. Users can participate as either speakers or audience members. As a speaker, users get real-time feedback and ratings from the audience, allowing them to refine their skills. The project incorporates a 3D scene rendered using Three.js and GLTF models to create an immersive experience, supported by backend functionality through Node.js. This document provides an in-depth explanation of the codebase used to implement the system.

index.html:
This HTML document represents a web application called StageCraft that allows users to provide feedback on a speaker's performance. The <head> section includes essential metadata such as character encoding (UTF-8) and a responsive viewport setup, along with links to an external CSS stylesheet for styling and Google Fonts for typography. It also defines an import map for using the Three.js library, which is crucial for 3D graphics, and imports an external JavaScript module (avatar.js) for avatar-related functionality. The <body> contains a structured layout with a sidebar for feedback submission, where users can rate the speaker on Confidence, Fluency, and Subject using buttons that capture scores from 1 to 5. Additionally, there is a section for a Feedback Summary displayed on a canvas element, where charts can be rendered. The main content area includes a container for an avatar, a loading message, an audio file upload input, and a button to reset the avatar's position. Finally, the document links to Chart.js for charting functionalities and Socket.io for real-time web socket communication, along with another JavaScript module (feedback.js) for handling feedback-related logic.

avatar.js:
This JavaScript code utilizes the Three.js library to create a 3D avatar that can animate based on audio input and user interactions. The loadModel function loads a 3D avatar model (avatar.glb) using the GLTFLoader, setting up the scene with lighting, camera controls (using OrbitControls), and handling loading progress with a loading message. The setupScene function configures the renderer, camera, and lighting, and it also identifies specific bones of the avatar (like the jawBone, leftHandBone, and rightHandBone) for animation. The avatar's talking animation is triggered by pressing the 'T' key, with event listeners for keydown and keyup events managing the animation state. Audio recording is handled using the MediaRecorder API, with functions startRecording and stopRecording managing the audio stream and processing it to play back while syncing the jaw movement to the audio amplitude through an AudioAnalyser. The resetToAttentionPosition function resets the avatar's pose after audio playback ends. The code also includes a socket connection to emit audio data, facilitating real-time communication. Key parts of the code include the loadModel, setupScene, startRecording, stopRecording, and resetToAttentionPosition functions, as well as the handling of avatar animations and audio playback.

feedback.js:
This JavaScript code initializes a feedback system that captures user ratings for a speaker's performance in three categories: Confidence, Fluency, and Subject. It waits for the DOMContentLoaded event to ensure the DOM is fully loaded before establishing a socket connection using Socket.io. It sets up an initial feedback data object to store ratings and initializes a Chart.js pie chart to visually represent these ratings. When users click on rating buttons, the corresponding category score is updated in the feedbackData object, and the chart is refreshed to reflect the new ratings. Additionally, the updated feedback data is emitted to the server via the socket connection. The code also listens for feedback updates from the server, allowing real-time synchronization of the feedback chart when data changes occur on the server side. Key components include the feedbackData object, the Chart.js initialization, and the socket event listeners for both sending and receiving feedback data.

backend: server.js:
This Node.js code sets up a basic server using Express and Socket.io to facilitate real-time communication among clients. It creates an HTTP server that serves static files from a "public" directory and listens for client connections via Socket.io. When a client connects, it logs the connection and sets up event listeners for various socket events: "screen-share" for initiating screen sharing, "update-feedback" for receiving feedback data from clients, and "audio-data" for handling audio data sent by clients. Each of these events broadcasts the received data to all other connected clients, ensuring that updates are shared in real time. The server also logs when a client disconnects and displays the total number of connected clients. Finally, the server listens on port 4000, and a message is logged to indicate that it is running. Key components include the Socket.io connection handling, event listeners for screen sharing, feedback updates, and audio sharing, as well as server initialization.

Website preview:
![Screenshot 2024-11-19 110230](https://github.com/user-attachments/assets/dec9cef2-617c-4173-846f-08de3b47e55e)

Website link: https://avatar-spectator.vercel.app/
